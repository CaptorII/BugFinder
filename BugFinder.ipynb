{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 1: BugFinder\n",
    "### Intro\n",
    "This notebook is to be the record of completion for Assessment 1: Machine Learning.\n",
    "### Scenario\n",
    "Develop a model to be used with a hand-held hyperspectral camera system to identify harmful pests on containers and vessels entering the country, with the aim of preventing those pests from establishing themselves in this country and destroying native wildlife. This project will use a standard camera to develop a proof of concept for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-setup\n",
    "%pip install -Uqq fastbook\n",
    "%pip install -Uqq fastai\n",
    "%pip install -Uqq ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - imports\n",
    "from fastai.vision.widgets import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Image.open(\"Insects/Achatina fulica Bowdich/b589ecb6-505d-444f-8753-f4988c11615b.jpg\")\n",
    "data.to_thumb(128,128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing & Organisation\n",
    "#### Locating Dataset\n",
    "I used Kaggle to research datasets containing images of a variety of different insects, and located two potentially suitable, pre-labelled data sets:\n",
    "- https://www.kaggle.com/datasets/shameinew/insect-images-with-scientific-names\n",
    "- https://www.kaggle.com/datasets/rtlmhjbn/ip02-dataset\n",
    "\n",
    "After examining these large datasets, I chose to take a subset of the first dataset as a proof of concept to specialise in identifying pests of highest concern. The following code is importing this dataset for use in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block for kaggle \n",
    "insect_types = ['Trogoderma granarium Everts', 'Solenopsis invicta Buren', 'Lymantria dispar (L.)', 'Achatina fulica Bowdich', 'Apis mellifera Linnaeus']\n",
    "path = Path('/kaggle/input/insects/Insects')\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "khapra_folder = path/insect_types[0]\n",
    "ant_folder = path/insect_types[1]\n",
    "moth_folder = path/insect_types[2]\n",
    "snail_folder = path/insect_types[3]\n",
    "bee_folder = path/insect_types[4]\n",
    "# count images in each folder, verify files have been located\n",
    "for name in insect_types:\n",
    "    dest = (path/name)\n",
    "    dest.mkdir(exist_ok=True)\n",
    "    count_images = sum(len(files) for _, _, files in os.walk(dest))\n",
    "    print(count_images)\n",
    "# show a bee to check images\n",
    "test_bee = Image.open(bee_folder/os.listdir(bee_folder)[0])\n",
    "test_bee.to_thumb(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insect_types = ['Trogoderma granarium Everts', 'Solenopsis invicta Buren', 'Lymantria dispar (L.)', 'Achatina fulica Bowdich', 'Apis mellifera Linnaeus']\n",
    "path = Path('Insects')\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "khapra_folder = path/insect_types[0]\n",
    "ant_folder = path/insect_types[1]\n",
    "moth_folder = path/insect_types[2]\n",
    "snail_folder = path/insect_types[3]\n",
    "bee_folder = path/insect_types[4]\n",
    "# count images in each folder, verify files have been located\n",
    "bug_counts = [0,0,0,0,0]\n",
    "for i, name in enumerate(insect_types):\n",
    "    dest = (path/name)\n",
    "    dest.mkdir(exist_ok=True)\n",
    "    bug_counts[i] = sum(len(files) for _, _, files in os.walk(dest))\n",
    "    print(name + \": \" + str(bug_counts[i]))\n",
    "# show a bee to check images\n",
    "test_bee = Image.open(bee_folder/os.listdir(bee_folder)[0])\n",
    "test_bee.to_thumb(128,128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Dataset\n",
    "The following code will take the pre-labelled dataset and correct the sizes of all images to a consistent size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5))\n",
    "datablock = datablock.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())\n",
    "dls = datablock.dataloaders(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Organisation\n",
    "The following code will split the dataset into a training folder, validation folder and testing folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_folders = [khapra_folder, ant_folder, moth_folder, snail_folder, bee_folder]\n",
    "for i, bug in enumerate(insect_types):\n",
    "    training_count = int(bug_counts[i] * 0.6)\n",
    "    validation_count = int(bug_counts[i] * 0.2)\n",
    "    test_count = int(bug_counts[i] * 0.2)\n",
    "    training_dest = (bug_folders[i]/'training')\n",
    "    training_dest.mkdir(exist_ok=True)\n",
    "    validation_dest = (bug_folders[i]/'validation')\n",
    "    validation_dest.mkdir(exist_ok=True)\n",
    "    test_dest = (bug_folders[i]/'test')\n",
    "    test_dest.mkdir(exist_ok=True)\n",
    "    for j, image in enumerate(bug_folders[i]):  # TypeError: 'WindowsPath' object is not iterable\n",
    "      if j < training_count:\n",
    "        shutil.copy(image, training_dest)\n",
    "      elif j >= training_count and j < training_count + validation_count:\n",
    "         shutil.copy(image, validation_dest)\n",
    "      else:\n",
    "         shutil.copy(image, test_dest)\n",
    "    print('# of training files: ' + sum(len(files) for _, _, files in os.walk(training_dest)))\n",
    "    print('# of validation files: ' + sum(len(files) for _, _, files in os.walk(validation_dest)))\n",
    "    print('# of test files: ' + sum(len(files) for _, _, files in os.walk(test_dest)))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ML Model:\n",
    "\n",
    "1. Utilize the fastai library to create an image classification model.\n",
    "2. Choose an appropriate deep learning architecture (e.g., CNN) for the model.\n",
    "3. Train the model using the training dataset, considering hyperparameter tuning.\n",
    "4. Monitor training progress and adjust if necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scoring:\n",
    "\n",
    "1. Use the trained model to predict pest species in a given set of images from the validation dataset.\n",
    "2. Evaluate the model's performance using appropriate metrics (e.g., accuracy, precision, recall).\n",
    "3. Visualize the model's predictions and actual labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Test Datasets:\n",
    "\n",
    "1. Create a validation dataset that was not used during training to assess the model's generalization ability.\n",
    "2. Ensure that the validation dataset contains images with varying conditions and perspectives.\n",
    "3. Additionally, prepare a separate test dataset for final model evaluation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Analysis:\n",
    "\n",
    "1. Apply the trained model to the test dataset to evaluate its performance on previously unseen data.\n",
    "2. Analyze the model's predictions, misclassifications, and potential areas of improvement.\n",
    "3. Summarize the assessment of the model's capabilities and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
