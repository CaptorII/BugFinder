{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 1: BugFinder\n",
    "### Intro\n",
    "This notebook is to be the record of completion for Assessment 1: Machine Learning.\n",
    "### Scenario\n",
    "Develop a model to be used with a hand-held hyperspectral camera system to identify harmful pests on containers and vessels entering the country, with the aim of preventing those pests from establishing themselves in this country and destroying native wildlife. This project will use a standard camera to develop a proof of concept for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-setup\n",
    "%pip install -Uqq ipywidgets\n",
    "%pip install -Uqq fastbook\n",
    "%pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - imports\n",
    "from fastai.vision.widgets import *\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Image.open(\"Insects/Achatina fulica Bowdich/b589ecb6-505d-444f-8753-f4988c11615b.jpg\")\n",
    "data.to_thumb(128,128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing & Organisation\n",
    "#### Locating Dataset\n",
    "I used Kaggle to research datasets containing images of a variety of different insects, and located two potentially suitable, pre-labelled data sets:\n",
    "- https://www.kaggle.com/datasets/shameinew/insect-images-with-scientific-names\n",
    "- https://www.kaggle.com/datasets/rtlmhjbn/ip02-dataset\n",
    "\n",
    "After examining these large datasets, I chose to take a subset of the first dataset as a proof of concept to specialise in identifying pests of highest concern. The following code is importing this dataset for use in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block for kaggle \n",
    "insect_types = ['Trogoderma granarium Everts', 'Solenopsis invicta Buren', 'Lymantria dispar (L.)', 'Achatina fulica Bowdich', 'Apis mellifera Linnaeus']\n",
    "path = Path('/kaggle/input/insects/Insects')\n",
    "if not path.exists():\n",
    "    path.mkdir()    \n",
    "bug_folders = []\n",
    "for i, folder in enumerate(insect_types):\n",
    "    bug_folders.append(Path('/kaggle/working/insects/' + folder))\n",
    "    if not bug_folders[i].exists():\n",
    "        os.makedirs(bug_folders[i])\n",
    "# count images in each folder, verify files have been located\n",
    "bug_counts = [0, 0, 0, 0, 0]\n",
    "for i, name in enumerate(insect_types):\n",
    "    bug_counts[i] = len(fnmatch.filter(os.listdir(bug_folders[i]), '*.*'))\n",
    "    print(name + \": \" + str(bug_counts[i]))\n",
    "# show a bee to check images\n",
    "test_bee = Image.open(bug_folders[4]/os.listdir(bug_folders[4])[0])\n",
    "test_bee.to_thumb(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insect_types = ['Trogoderma granarium Everts', 'Solenopsis invicta Buren', 'Lymantria dispar (L.)', 'Achatina fulica Bowdich', 'Apis mellifera Linnaeus']\n",
    "path = Path('Insects')\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "# find/create subfolders for each insect type\n",
    "bug_folders = []\n",
    "for i, folder in enumerate(insect_types):\n",
    "    bug_folders.append(path/folder)\n",
    "    if not bug_folders[i].exists():\n",
    "        os.makedirs(bug_folders[i])\n",
    "# count images in each folder, verify files have been located\n",
    "bug_counts = [0, 0, 0, 0, 0]\n",
    "for i, name in enumerate(insect_types):\n",
    "    bug_counts[i] = len(fnmatch.filter(os.listdir(bug_folders[i]), '*.*'))\n",
    "    print(name + \": \" + str(bug_counts[i]))\n",
    "# show a bee to check images\n",
    "test_bee = Image.open(bug_folders[4]/os.listdir(bug_folders[4])[0])\n",
    "test_bee.to_thumb(128,128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Dataset\n",
    "The following code will take the pre-labelled dataset and correct the sizes of all images to a consistent size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5))\n",
    "datablock = datablock.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())\n",
    "dls = datablock.dataloaders(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Organisation\n",
    "The following code will split the dataset into a training folder, validation folder and testing folder, then output the number of images in the newly sorted folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bug in enumerate(insect_types):\n",
    "    training_count = int(bug_counts[i] * 0.6)\n",
    "    validation_count = int(bug_counts[i] * 0.2)\n",
    "    training_dest = (path/'training'/insect_types[i])\n",
    "    if not training_dest.exists():\n",
    "      os.makedirs(training_dest)\n",
    "    validation_dest = (path/'validation'/insect_types[i])\n",
    "    if not validation_dest.exists():\n",
    "      os.makedirs(validation_dest)\n",
    "    test_dest = (path/'test'/insect_types[i])\n",
    "    if not test_dest.exists():\n",
    "      os.makedirs(test_dest)\n",
    "    files = os.listdir(bug_folders[i])\n",
    "    for j, image in enumerate(files):\n",
    "      if j < training_count:\n",
    "        shutil.copy(bug_folders[i]/image, training_dest)\n",
    "      elif j < training_count + validation_count:\n",
    "        shutil.copy(bug_folders[i]/image, validation_dest)\n",
    "      elif j < len(files) - 3:\n",
    "        shutil.copy(bug_folders[i]/image, test_dest)\n",
    "    # count files in sorted folders and print results\n",
    "    training_files = [[file] for file in os.listdir(training_dest)]\n",
    "    validation_files = [[file] for file in os.listdir(validation_dest)]\n",
    "    test_files = [[file] for file in os.listdir(test_dest)]\n",
    "    print(bug + ' training files: ' + str(len(training_files)))\n",
    "    print(bug + ' validation files: ' + str(len(validation_files)))\n",
    "    print(bug + ' test files: ' + str(len(test_files)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ML Model:\n",
    "\n",
    "The following code will create and train an image classification model based on the resnet18 pre-trained model as a base, as it is commonly used in industry due to being relatively quick to train for good accuracy. The parameters have been tweaked to be optimised for training quickly for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scoring:\n",
    "\n",
    "1. Use the trained model to predict pest species in a given set of images from the validation dataset.\n",
    "2. Evaluate the model's performance using appropriate metrics (e.g., accuracy, precision, recall).\n",
    "3. Visualize the model's predictions and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Test Datasets:\n",
    "\n",
    "1. Create a validation dataset that was not used during training to assess the model's generalization ability.\n",
    "2. Ensure that the validation dataset contains images with varying conditions and perspectives.\n",
    "3. Additionally, prepare a separate test dataset for final model evaluation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Analysis:\n",
    "\n",
    "1. Apply the trained model to the test dataset to evaluate its performance on previously unseen data.\n",
    "2. Analyze the model's predictions, misclassifications, and potential areas of improvement.\n",
    "3. Summarize the assessment of the model's capabilities and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
